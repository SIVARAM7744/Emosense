import cv2
import numpy as np
from tensorflow.keras.models import load_model
from tkinter import Tk, Canvas, Label, font
from PIL import Image, ImageTk

# Load the saved model
loaded_model = load_model("T:/emotion detection ML model/facialemotionmodel.h5")

# Initialize the face detector from OpenCV
face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')

# Emotion labels and their corresponding responses
emotion_responses = {
    'Angry': "Take a deep breath, count to 10, and relax.",
    'Disgust': "It's okay not to like everything. Find something that makes you happy!",
    'Fear': "Remember, facing your fears is the first step to overcoming them.",
    'Happy': "Embrace the joy! What's something that makes you smile?",
    'Sad': "It's okay not to be okay. Take your time and do something you love.",
    'Surprise': "Life is full of surprises! What's something unexpected that made you happy?",
    'Neutral': "Feeling neutral today? That's alright, find something to spark your curiosity."
}

# Create Tkinter window
root = Tk()
root.title("Real-time Emotion Detection")
root.geometry("800x600")

# Set a custom font and background color
custom_font = font.Font(family="Helvetica", size=16, weight="bold")
root.configure(bg="#1c1c1c")

# Initialize Canvas for displaying webcam feed
canvas = Canvas(root, width=800, height=450, bg="#262626")
canvas.pack()

# Initialize Label for displaying detected emotion
emotion_label = Label(root, text="", font=custom_font, fg="#ffffff", bg="#1c1c1c")
emotion_label.pack()

# Initialize webcam
cap = cv2.VideoCapture(0)

def update():
    _, frame = cap.read()

    # Convert the frame to grayscale
    gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)

    # Detect faces in the frame
    faces = face_cascade.detectMultiScale(gray_frame, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))

    # Process each detected face
    for (x, y, w, h) in faces:
        # Extract the face region
        face_roi = gray_frame[y:y + h, x:x + w]

        # Preprocess the face region
        face_roi = cv2.resize(face_roi, (48, 48))
        face_roi = face_roi / 255.0
        face_roi = np.expand_dims(face_roi, axis=-1)
        face_roi = np.expand_dims(face_roi, axis=0)

        # Make a prediction using the loaded model
        prediction = loaded_model.predict(face_roi)

        # Get the predicted emotion
        emotion_labels = ['Angry', 'Disgust', 'Fear', 'Happy', 'Sad', 'Surprise', 'Neutral']
        predicted_emotion = emotion_labels[np.argmax(prediction)]

        # Display the predicted emotion
        cv2.putText(frame, f"Emotion: {predicted_emotion}", (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)

        # Update the detected emotion response in the GUI
        if predicted_emotion in emotion_responses:
            emotion_label.config(text=emotion_responses[predicted_emotion])

    # Convert the OpenCV frame to an ImageTk format
    frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)  # Convert color from BGR to RGB
    img = Image.fromarray(frame)
    img = ImageTk.PhotoImage(image=img)

    # Update the canvas with the new image
    canvas.img = img  # Save reference to avoid garbage collection
    canvas.create_image(400, 225, anchor="center", image=img)

    # Schedule the update function to be called again after 10 milliseconds
    root.after(10, update)

# Start the update loop
update()

# Run the Tkinter main loop
root.mainloop()

# Release the webcam when the application is closed
cap.release()